{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generated = json.load(open('eval_generations/eval_7b_testv1_train/api_data_0_468.json', 'r'))\n",
    "data_ground_truth = json.load(open('ToolAlpaca/data/train_data.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на то, какой длины цепочки в ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for item in data_ground_truth:\n",
    "    for chain in item['Instances']:\n",
    "        if 'intermediate_steps' in chain:\n",
    "            lengths.append(len(chain['intermediate_steps']))\n",
    "Counter(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generated[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "count = 0\n",
    "for idx, (chain_pred, chain_gt) in enumerate(zip(data_generated, data_ground_truth)):\n",
    "    for query, steps_pred, steps_gt in zip(chain_pred['Instructions'], \n",
    "                                           chain_pred['Instances'], \n",
    "                                           chain_gt['Instances']):\n",
    "        if not 'intermediate_steps' in steps_pred:\n",
    "            errors.append({\n",
    "                'tool_set_num': idx,\n",
    "                'type': 'other_error_pred',\n",
    "                'query': query,\n",
    "                'steps_pred': steps_pred,\n",
    "                'steps_gt': steps_gt,\n",
    "            })\n",
    "            count += 1\n",
    "            continue\n",
    "        if not 'intermediate_steps' in steps_gt:\n",
    "            errors.append({\n",
    "                'tool_set_num': idx,\n",
    "                'type': 'other_error_gt',\n",
    "                'query': query,\n",
    "                'steps_pred': steps_pred,\n",
    "                'steps_gt': steps_gt,\n",
    "            })\n",
    "            count += 1\n",
    "            continue\n",
    "        if len(steps_pred['intermediate_steps']) == 0 or len(steps_gt['intermediate_steps']) == 0:\n",
    "            count += 1\n",
    "            continue\n",
    "        steps_pred = steps_pred['intermediate_steps'][0][0]\n",
    "        steps_gt = steps_gt['intermediate_steps'][0][0]\n",
    "        if steps_pred[0] != steps_gt[0]:\n",
    "            errors.append({\n",
    "                'tool_set_num': idx,\n",
    "                'type': 'name_error',\n",
    "                'query': query,\n",
    "                'steps_pred': steps_pred,\n",
    "                'steps_gt': steps_gt,\n",
    "            })\n",
    "            count += 1\n",
    "        else: \n",
    "            try: \n",
    "                params_pred = json.loads(steps_pred[1])\n",
    "                params_gt = json.loads(steps_gt[1])\n",
    "                if params_gt != params_pred:\n",
    "                    errors.append({\n",
    "                        'tool_set_num': idx,\n",
    "                        'type': 'parameter_error',\n",
    "                        'query': query,\n",
    "                        'steps_pred': steps_pred,\n",
    "                        'steps_gt': steps_gt,\n",
    "                    })\n",
    "                    count += 1\n",
    "            except json.decoder.JSONDecodeError as err:\n",
    "                errors.append({\n",
    "                    'tool_set_num': idx,\n",
    "                    'type': 'parameter_error',\n",
    "                    'query': query,\n",
    "                    'steps_pred': steps_pred,\n",
    "                    'steps_gt': steps_gt,\n",
    "                })\n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('ToolAlpaca')\n",
    "from utils import load_openapi_spec, analyze_openapi_spec\n",
    "import json\n",
    "from agent.convert_request import call_api_function\n",
    "from utils import load_openapi_spec, escape\n",
    "from agent.tools import Tool, GetDetailsTool, tool_projection\n",
    "\n",
    "def load_tools(api_data):\n",
    "    server_url = \"http://127.0.0.1:5678\"\n",
    "    openapi_spec = load_openapi_spec(api_data[\"Documentation\"], replace_refs=True)\n",
    "    components_descriptions = escape(api_data[\"Function_Description\"][\"components\"])\n",
    "    tools = dict()\n",
    "    for idx, func_name in enumerate(api_data[\"Function_Projection\"]):\n",
    "        description = escape(api_data[\"Function_Description\"][func_name])\n",
    "        if idx == len(api_data[\"Function_Projection\"]) - 1:\n",
    "            description += components_descriptions\n",
    "        path, method = api_data[\"Function_Projection\"][func_name]\n",
    "        tools[func_name] = Tool(\n",
    "            base_url=server_url + \"/\" + api_data[\"Name\"] if server_url else None,\n",
    "            func_name=func_name,\n",
    "            openapi_spec=openapi_spec,\n",
    "            path=path,\n",
    "            method=method,\n",
    "            description=description,\n",
    "            retrieval_available=\"retrieval\" in api_data.get(\"external_tools\", [])\n",
    "        )\n",
    "    return tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for item in tqdm(errors):\n",
    "    if not 'error' in item['steps_gt'] and not 'error' in item['steps_pred'] and item['type'] == 'name_error':\n",
    "        tool_set = load_tools(data_ground_truth[item['tool_set_num']])\n",
    "        tool_name_pred = item['steps_pred'][0]\n",
    "        tool_params_pred = item['steps_pred'][1]    \n",
    "        tool_res_pred = tool_set[tool_name_pred](tool_params_pred)\n",
    "        tool_name_gt = item['steps_gt'][0]\n",
    "        tool_params_gt = item['steps_gt'][1]\n",
    "        tool_res_gt = tool_set[tool_name_gt](tool_params_gt)\n",
    "        print(tool_name_pred)\n",
    "        print(tool_params_pred)\n",
    "        print(tool_res_pred)\n",
    "        print(tool_name_gt)\n",
    "        print(tool_params_gt)\n",
    "        print(tool_res_gt)\n",
    "        print('#' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tool_params_pred)\n",
    "print(tool_res_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tool_params_gt)\n",
    "print(tool_res_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_set[tool_name_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, есть ли примеры с error в поле входа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_halluc = 0\n",
    "for item in tqdm(errors):\n",
    "    if 'error' in item['steps_pred']:\n",
    "        pprint.pprint(item)\n",
    "        print('#' * 100)\n",
    "        errors_halluc += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько всего ошибок с \"other error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_errors_gt = 0\n",
    "for item in errors:\n",
    "    if item['type'] == 'other_error_gt':\n",
    "        pprint(item)\n",
    "        other_errors_gt += 1\n",
    "\n",
    "other_errors_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_errors_pred = 0\n",
    "for item in errors:\n",
    "    if item['type'] == 'other_error_pred':\n",
    "        pprint(item)\n",
    "        other_errors_pred += 1\n",
    "\n",
    "other_errors_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, есть ли примеры, в которых в prediction просто нет нужного тула"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_hallucination_names = 0\n",
    "for item in tqdm(errors):\n",
    "    if item['type'] != 'other_error_pred' and item['type'] != 'other_error_gt':\n",
    "        tool_set = data_ground_truth[item['tool_set_num']]['Function_Description']\n",
    "        pred_tool_name = item['steps_pred'][0]\n",
    "        gt_tool_name = item['steps_gt'][0]\n",
    "        if pred_tool_name not in tool_set:\n",
    "            pprint(tool_set)\n",
    "            pprint(item)\n",
    "            count_hallucination_names += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_hallucination_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, есть ли примеры, где модель использовала тул, которого нет в промпте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_not_in_tool_set = 0\n",
    "for idx, chain_pred in enumerate(data_generated):\n",
    "    tool_set = chain_pred['Function_Description']\n",
    "    for query, steps_pred in zip(chain_pred['Instructions'], chain_pred['Instances']):                           \n",
    "        if not 'intermediate_steps' in steps_pred:\n",
    "            continue\n",
    "        if len(steps_pred['intermediate_steps']) == 0:\n",
    "            continue\n",
    "        steps_pred = steps_pred['intermediate_steps'][0][0]\n",
    "        if steps_pred[0] not in tool_set:\n",
    "            pprint(steps_pred)\n",
    "            count_not_in_tool_set += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_not_in_tool_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем распарсить параметры тулов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tool_names_params_parseble = dict()\n",
    "all_tools_count = 0\n",
    "for idx, chain_pred in enumerate(data_generated):\n",
    "    tool_set = chain_pred['Function_Description']\n",
    "    for key, val in tool_set.items():\n",
    "        all_tools_count += 1\n",
    "        if val:\n",
    "            try:\n",
    "                print(key)\n",
    "                print(val)\n",
    "                tool_params = json.loads(val.split('Parameters: ')[1].split('\\nOutput:')[0])\n",
    "                print(tool_params)\n",
    "                print('#' * 100)\n",
    "\n",
    "                all_tool_names_params_parseble[key] = tool_params\n",
    "            except Exception as e:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tool_names_params_parseble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_tool_names_params_parseble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tools_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем пройтись по всем вызовам тулов с ошибками и посмотреть на примеры, в которых нету каких-то параметров "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_count_wrong_param_names = 0\n",
    "error_count_no_required_params = 0\n",
    "count_correct_gt_uncorrect_pred = 0\n",
    "for item in tqdm(errors):\n",
    "    if item['type'] != 'other_error_pred' and item['type'] != 'other_error_gt':\n",
    "        pred_tool_name = item['steps_pred'][0]\n",
    "        pred_tool_params = item['steps_pred'][1]\n",
    "        gt_tool_name = item['steps_gt'][0]\n",
    "        gt_tool_params = item['steps_gt'][1]\n",
    "        res = check_wrong_or_required_params(pred_tool_name, pred_tool_params)\n",
    "        if not res[0]:\n",
    "            if res[1] == 'wrong':\n",
    "                error_count_wrong_param_names += 1\n",
    "            else:\n",
    "                error_count_no_required_params += 1\n",
    "        res_gt = check_wrong_or_required_params(gt_tool_name, gt_tool_params)\n",
    "        print(item)\n",
    "        print(res_gt)\n",
    "        if res_gt[0] and not res[0]:\n",
    "            count_correct_gt_uncorrect_pred += 1\n",
    "            pprint(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_count_wrong_param_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_count_no_required_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_correct_gt_uncorrect_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем вывести все примеры, в которых в ground_truth нет ошибок, а в prediction есть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_wrong_or_required_params(tool_name, tool_params):\n",
    "    if tool_name in all_tool_names_params_parseble:\n",
    "            tool_param_descriptions = all_tool_names_params_parseble[tool_name]\n",
    "            for param in tool_params:\n",
    "                if param not in tool_param_descriptions:\n",
    "                    return (False, 'wrong')\n",
    "            for param in tool_param_descriptions:\n",
    "                if 'required' in tool_param_descriptions[param].lower():\n",
    "                    if not param in tool_params:\n",
    "                        return (False, 'no_required')\n",
    "\n",
    "    return (True, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем почистить трейн и выделить все примеры, в которых есть корректный вызов тулов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = []\n",
    "cleaned_train = []\n",
    "\n",
    "for item in data_ground_truth:\n",
    "    for steps in item['Instances']:\n",
    "        flag = True\n",
    "        try:\n",
    "            for item in steps['intermediate_steps']:\n",
    "                gt_tool_name = item[0][0]\n",
    "                gt_tool_params = json.loads(item[0][1])\n",
    "                if not check_wrong_or_required_params(gt_tool_name, gt_tool_params)[0]:\n",
    "                    flag = False\n",
    "        except:\n",
    "            flag = False\n",
    "        if flag:\n",
    "            cleaned_train.append(steps)\n",
    "        all_train.append(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaned_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем почистить трейн и погенерировать ошибки на очищенном трейне"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько данных в оригинальном трейне"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_preprocessed = json.load(open('data/train_data_preprocessed', 'r'))\n",
    "len(train_data_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, использует ли модель вообще в тесте тул getDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generations = json.load(open('eval_generations/eval_7b_testv1_simulated/api_data_0_10.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tool_chains = 0\n",
    "tool_chains_w_getdetails = 0\n",
    "\n",
    "for item in test_generations:\n",
    "    for steps in item['Instances']:\n",
    "        if 'intermediate_steps' in steps:\n",
    "            for item in steps['intermediate_steps']:\n",
    "                gt_tool_name = item[0][0]\n",
    "                if gt_tool_name == 'getDetails':\n",
    "                    tool_chains_w_getdetails += 1\n",
    "                    break\n",
    "            all_tool_chains += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tool_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_chains_w_getdetails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры с getDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_count_wrong_param_names = 0\n",
    "error_count_no_required_params = 0\n",
    "count_correct_gt_uncorrect_pred = 0\n",
    "exception_errors = 0\n",
    "for item in tqdm(errors):\n",
    "    try:\n",
    "        if item['type'] != 'other_error_pred' and item['type'] != 'other_error_gt':\n",
    "            pred_tool_name = item['steps_pred'][0]\n",
    "            pred_tool_params = json.loads(item['steps_pred'][1])\n",
    "            gt_tool_name = item['steps_gt'][0]\n",
    "            gt_tool_params = json.loads(item['steps_gt'][1])\n",
    "            res = check_wrong_or_required_params(pred_tool_name, pred_tool_params)\n",
    "            if not res[0]:\n",
    "                if res[1] == 'wrong':\n",
    "                    error_count_wrong_param_names += 1\n",
    "                else:\n",
    "                    error_count_no_required_params += 1\n",
    "            res_gt = check_wrong_or_required_params(gt_tool_name, gt_tool_params)\n",
    "            if res_gt[0] and not res[0]:\n",
    "                count_correct_gt_uncorrect_pred += 1\n",
    "                pprint(item)\n",
    "    except:\n",
    "        exception_errors += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_count_wrong_param_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_count_no_required_params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_correct_gt_uncorrect_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exception_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tool_names_params_parseble['getElevation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tool_names_params_parseble['filterByArea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tool_names_params_parseble['getTicker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tool_names_params_parseble['getAcco']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тест функции проверки параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_wrong_or_required_params(tool_name, tool_params):\n",
    "    if tool_name in all_tool_names_params_parseble:\n",
    "            tool_param_descriptions = all_tool_names_params_parseble[tool_name]\n",
    "            for param in tool_params:\n",
    "                if param not in tool_param_descriptions:\n",
    "                    return (False, 'wrong')\n",
    "            for param in tool_param_descriptions:\n",
    "                if 'required' in tool_param_descriptions[param].lower():\n",
    "                    if not param in tool_params:\n",
    "                        return (False, 'no_required')\n",
    "    return (True, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_wrong_or_required_params('getElevation', {\"latitude\": 34.25, \"longitude\": -71.02})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация примеров с ошибками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_w_error_corrections = deepcopy(data_ground_truth)\n",
    "\n",
    "sample_w_error_corrections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_w_error_corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составим примеры с ошибками, которые мы можем детектировать с помощью неправильных параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_w_error_corrections = deepcopy(data_ground_truth)\n",
    "\n",
    "count = 0\n",
    "error_count = 0\n",
    "count_non_gt_non_pred = 0\n",
    "count_non_gt_pred = 0\n",
    "count_gt_pred = 0\n",
    "count_gt_non_pred = 0\n",
    "for idx, (chain_pred, chain_gt) in enumerate(zip(data_generated, data_ground_truth)):\n",
    "    sample_w_error_corrections[idx]['Instructions'] = []\n",
    "    sample_w_error_corrections[idx]['Instances'] = []\n",
    "    \n",
    "    for query_pred, query_gt, steps_pred, steps_gt in zip(chain_pred['Instructions'],\n",
    "                                                          chain_gt['Instructions'],  \n",
    "                                                          chain_pred['Instances'],\n",
    "                                                          chain_gt['Instances']):\n",
    "        \n",
    "        assert query_pred == query_gt\n",
    "        if ('intermediate_steps' in steps_gt and 'intermediate_steps' in steps_pred and \n",
    "            len(steps_gt['intermediate_steps']) != 0 and len(steps_pred['intermediate_steps']) != 0):\n",
    "                try:\n",
    "                    item_gt, item_pred = steps_gt['intermediate_steps'][0], steps_pred['intermediate_steps'][0]\n",
    "                    pred_tool_name = item_pred[0][0]\n",
    "                    pred_tool_params = yaml.load(item_pred[0][1], yaml.Loader)\n",
    "                    gt_tool_name = item_gt[0][0]\n",
    "                    gt_tool_params = yaml.load(item_gt[0][1], yaml.Loader)\n",
    "                    res_pred = check_wrong_or_required_params(pred_tool_name, pred_tool_params)\n",
    "                    res_gt = check_wrong_or_required_params(gt_tool_name, gt_tool_params)                                \n",
    "                    if res_gt[0] and not res_pred[0]:\n",
    "                        sample_w_error_corrections[idx]['Instructions'].append(query_gt)\n",
    "                        item_gt_copy = deepcopy(steps_gt)\n",
    "                        item_gt_copy['intermediate_steps'] = item_pred + item_gt_copy['intermediate_steps']\n",
    "                        sample_w_error_corrections[idx]['Instances'].append(item_gt_copy)\n",
    "                        count_gt_non_pred += 1\n",
    "                    elif not res_gt[0] and not res_pred[0]:\n",
    "                         count_non_gt_non_pred += 1\n",
    "                    elif not res_gt[0] and res_pred[0]:\n",
    "                         count_non_gt_pred += 1\n",
    "                    elif res_gt[0] and res_pred[0]:\n",
    "                         count_gt_pred += 1\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    error_count += 1\n",
    "                    print('#' * 100)\n",
    "\n",
    "count_correction_examples = 0\n",
    "sample_w_error_corrections_final = []\n",
    "for item in sample_w_error_corrections:\n",
    "    if len(item['Instructions']) > 0:\n",
    "        sample_w_error_corrections_final.append(item)\n",
    "        count_correction_examples += len(item['Instructions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_gt_non_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_gt_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_non_gt_non_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_non_gt_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tool_names_params_parseble['getEventDetails']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_correction_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_w_error_corrections_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(sample_w_error_corrections_final, open('data/correction_examples_wrong_params_no_thoughts.json', 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почистим трейн от примеров, где нету instance, где хотя бы во одном шаге есть ошибка с параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train = deepcopy(data_ground_truth)\n",
    "\n",
    "for idx, chain_gt in enumerate(data_ground_truth):\n",
    "    cleaned_train[idx]['Instructions'] = []\n",
    "    cleaned_train[idx]['Instances'] = []\n",
    "\n",
    "    for query_gt, steps_gt in zip(chain_gt['Instructions'], chain_gt['Instances']):\n",
    "        if 'intermediate_steps' in steps_gt and len(steps_gt['intermediate_steps']) != 0:\n",
    "            try:\n",
    "                flag = True\n",
    "                for item_gt in steps_gt['intermediate_steps']:\n",
    "                    gt_tool_name = item_gt[0][0]\n",
    "                    gt_tool_params = yaml.load(item_gt[0][1], yaml.Loader)\n",
    "                    res_gt = check_wrong_or_required_params(gt_tool_name, gt_tool_params)\n",
    "                    if not res_gt[0]:\n",
    "                        flag = False\n",
    "                if flag:\n",
    "                    cleaned_train[idx]['Instructions'].append(query_gt)\n",
    "                    cleaned_train[idx]['Instances'].append(steps_gt)\n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dirty_train_examples = 0\n",
    "for item in data_ground_truth:\n",
    "    num_dirty_train_examples += len(item['Instances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cleaned_train_examples = 0\n",
    "for item in cleaned_train:\n",
    "    num_cleaned_train_examples += len(item['Instances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cleaned_train_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dirty_train_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним эту предварительную версию трейна, чтобы на ней потом обучить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(cleaned_train,  open('ToolAlpaca/data/cleaned_train_v1.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим промпт и вызов ChatGPT для генерации ответов тулов с ошибками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tool_names_params_parseble['getWeatherForecast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_w_error_corrections_error_from_tools = deepcopy(sample_w_error_corrections_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in sample_w_error_corrections_final:\n",
    "    tool_set = load_tools(item)\n",
    "    for chain in item['Instances']:\n",
    "        name = chain['intermediate_steps'][0][0]\n",
    "        incorrect_params = chain['intermediate_steps'][0][1]\n",
    "        incorrect_params = '{\"location\": \"Marbella\", \"days\": 7, \"kek\": \"True\"}'\n",
    "        tool = tool_set[name]\n",
    "        print(name, incorrect_params)\n",
    "        print(tool)\n",
    "        output = tool._run(incorrect_params)\n",
    "        print(output)\n",
    "        print('#' * 100)\n",
    "        print(name, incorrect_params)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_set['searchJobs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скорее всего, я неправильно детектил ошибки. Пересоберу трейн с коррекшоном"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_params(tool_name, tool_params, curr_tool_descriptions_parseble, all_tool_names):\n",
    "    if tool_name not in all_tool_names:\n",
    "        return (False, 'wrong_name')\n",
    "    if tool_name in curr_tool_descriptions_parseble:\n",
    "        tool_param_descriptions = curr_tool_descriptions_parseble[tool_name]\n",
    "        for param in tool_params:\n",
    "            if param not in tool_param_descriptions:\n",
    "                return (False, 'wrong')\n",
    "        for param in tool_param_descriptions:\n",
    "            if 'required' in tool_param_descriptions[param].lower():\n",
    "                if not param in tool_params:\n",
    "                    return (False, 'no_required')\n",
    "    return (True, '')\n",
    "\n",
    "sample_w_error_corrections = deepcopy(data_ground_truth)\n",
    "\n",
    "count = 0\n",
    "error_count = 0\n",
    "count_non_gt_non_pred = 0\n",
    "count_non_gt_pred = 0\n",
    "count_gt_pred = 0\n",
    "count_gt_non_pred = 0\n",
    "for idx, (chain_pred, chain_gt) in enumerate(zip(data_generated, data_ground_truth)):\n",
    "    sample_w_error_corrections[idx]['Instructions'] = []\n",
    "    sample_w_error_corrections[idx]['Instances'] = []\n",
    "\n",
    "    # parsing tool descriptions\n",
    "    curr_tool_descriptions_parseble = dict()\n",
    "    tool_set = chain_pred['Function_Description']\n",
    "    for key, val in tool_set.items():\n",
    "        all_tools_count += 1\n",
    "        if val:\n",
    "            try:\n",
    "                tool_params = json.loads(val.split('Parameters: ')[1].split('\\nOutput:')[0])\n",
    "                curr_tool_descriptions_parseble[key] = tool_params\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    tool_set['retrieval'] = None\n",
    "    tool_set['datetime'] = None\n",
    "    tool_set['getDetails'] = None\n",
    "    for query_pred, query_gt, steps_pred, steps_gt in zip(chain_pred['Instructions'],\n",
    "                                                          chain_gt['Instructions'],  \n",
    "                                                          chain_pred['Instances'],\n",
    "                                                          chain_gt['Instances']):\n",
    "        \n",
    "        assert query_pred == query_gt\n",
    "        if ('intermediate_steps' in steps_gt and 'intermediate_steps' in steps_pred and \n",
    "            len(steps_gt['intermediate_steps']) != 0 and len(steps_pred['intermediate_steps']) != 0):\n",
    "                try:\n",
    "                    item_gt, item_pred = steps_gt['intermediate_steps'][0], steps_pred['intermediate_steps'][0]\n",
    "                    pred_tool_name = item_pred[0][0]\n",
    "                    pred_tool_params = yaml.load(item_pred[0][1], yaml.Loader)\n",
    "                    gt_tool_name = item_gt[0][0]\n",
    "                    gt_tool_params = yaml.load(item_gt[0][1], yaml.Loader)\n",
    "                    res_pred = check_params(pred_tool_name, pred_tool_params, curr_tool_descriptions_parseble, tool_set)\n",
    "                    res_gt = check_params(gt_tool_name, gt_tool_params, curr_tool_descriptions_parseble, tool_set)                                \n",
    "                    if res_gt[0] and not res_pred[0]:\n",
    "                        sample_w_error_corrections[idx]['Instructions'].append(query_gt)\n",
    "                        item_gt_copy = deepcopy(steps_gt)\n",
    "                        item_gt_copy['intermediate_steps'] = [item_pred] + item_gt_copy['intermediate_steps']\n",
    "                        sample_w_error_corrections[idx]['Instances'].append(item_gt_copy)\n",
    "                        count_gt_non_pred += 1\n",
    "                    elif not res_gt[0] and not res_pred[0]:\n",
    "                        print(pred_tool_name, pred_tool_params, res_pred)\n",
    "                        print(gt_tool_name, gt_tool_params, res_gt)\n",
    "                        print('#' * 100)\n",
    "                        count_non_gt_non_pred += 1\n",
    "                    elif not res_gt[0] and res_pred[0]:\n",
    "                        count_non_gt_pred += 1\n",
    "                    elif res_gt[0] and res_pred[0]:\n",
    "                        count_gt_pred += 1\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    error_count += 1\n",
    "                    print('#' * 100)\n",
    "\n",
    "count_correction_examples = 0\n",
    "sample_w_error_corrections_final = []\n",
    "for item in sample_w_error_corrections:\n",
    "    if len(item['Instructions']) > 0:\n",
    "        sample_w_error_corrections_final.append(item)\n",
    "        count_correction_examples += len(item['Instructions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_non_gt_non_pred)\n",
    "print(count_non_gt_pred)\n",
    "print(count_gt_pred)\n",
    "print(count_gt_non_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим ChatGPT на примерах, которые мы собрали"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.tools import CustomInvalidTool\n",
    "invalidtool = CustomInvalidTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_w_error_corrections_final_w_gpt_output = deepcopy(sample_w_error_corrections_final)\n",
    "\n",
    "count = 0\n",
    "for item in sample_w_error_corrections_final_w_gpt_output:\n",
    "    tool_set = load_tools(item)\n",
    "    tool_set['retrieval'] = None\n",
    "    tool_set['datetime'] = None\n",
    "    tool_set['getDetails'] = None\n",
    "    for chain in item['Instances']:\n",
    "        name = chain['intermediate_steps'][0][0][0]\n",
    "        incorrect_params = chain['intermediate_steps'][0][0][1]\n",
    "        if name in tool_set:\n",
    "            tool = tool_set[name]\n",
    "            print(name, incorrect_params)\n",
    "            print(tool)\n",
    "            output = tool._run(incorrect_params)\n",
    "            print(output)\n",
    "            print('#' * 100)\n",
    "            count += 1\n",
    "        else:\n",
    "            print(name, incorrect_params)\n",
    "            print(invalidtool)\n",
    "            output = invalidtool._run(None, name, list(tool_set.keys()))\n",
    "            print(output)\n",
    "            print('#' * 100)\n",
    "            count += 1\n",
    "        chain['intermediate_steps'][0][-1] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_correction_examples = 0\n",
    "for item in sample_w_error_corrections_final_w_gpt_output:\n",
    "    if len(item['Instructions']) > 0:\n",
    "        count_correction_examples += len(item['Instructions'])\n",
    "\n",
    "count_correction_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(sample_w_error_corrections_final_w_gpt_output, open('data/correction_examples_wrong_params.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пересоберу очищенный трейн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train = deepcopy(data_ground_truth)\n",
    "\n",
    "for idx, chain_gt in enumerate(data_ground_truth):\n",
    "    cleaned_train[idx]['Instructions'] = []\n",
    "    cleaned_train[idx]['Instances'] = []\n",
    "\n",
    "    curr_tool_descriptions_parseble = dict()\n",
    "    tool_set = chain_gt['Function_Description']\n",
    "    for key, val in tool_set.items():\n",
    "        all_tools_count += 1\n",
    "        if val:\n",
    "            try:\n",
    "                tool_params = json.loads(val.split('Parameters: ')[1].split('\\nOutput:')[0])\n",
    "                curr_tool_descriptions_parseble[key] = tool_params\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    tool_set['retrieval'] = None\n",
    "    tool_set['datetime'] = None\n",
    "    tool_set['getDetails'] = None\n",
    "\n",
    "    for query_gt, steps_gt in zip(chain_gt['Instructions'], chain_gt['Instances']):\n",
    "        if 'intermediate_steps' in steps_gt and len(steps_gt['intermediate_steps']) != 0:\n",
    "            try:\n",
    "                flag = True\n",
    "                for item_gt in steps_gt['intermediate_steps']:\n",
    "                    gt_tool_name = item_gt[0][0]\n",
    "                    gt_tool_params = yaml.load(item_gt[0][1], yaml.Loader)\n",
    "                    res_gt = check_params(gt_tool_name, gt_tool_params, \n",
    "                                          curr_tool_descriptions_parseble,\n",
    "                                          tool_set)\n",
    "                    if not res_gt[0]:\n",
    "                        flag = False\n",
    "                if flag:\n",
    "                    cleaned_train[idx]['Instructions'].append(query_gt)\n",
    "                    cleaned_train[idx]['Instances'].append(steps_gt)\n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cleaned_train_examples = 0\n",
    "for item in cleaned_train:\n",
    "    num_cleaned_train_examples += len(item['Instances'])\n",
    "num_cleaned_train_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dirty_train_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(cleaned_train,  open('data/cleaned_train_v2_correct.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подклею ошибки с галлюцинациями в очищенный трейн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_w_hallucinations = deepcopy(data_ground_truth)\n",
    "count_hallucinations = 0\n",
    "\n",
    "for idx, (chain_pred, chain_gt) in enumerate(zip(data_generated, data_ground_truth)):\n",
    "    sample_w_hallucinations[idx]['Instructions'] = []\n",
    "    sample_w_hallucinations[idx]['Instances'] = []\n",
    "\n",
    "    for query_pred, query_gt, steps_pred, steps_gt in zip(chain_pred['Instructions'],\n",
    "                                                          chain_gt['Instructions'],  \n",
    "                                                          chain_pred['Instances'],\n",
    "                                                          chain_gt['Instances']):\n",
    "        \n",
    "        if not 'intermediate_steps' in steps_pred and 'intermediate_steps' in steps_gt and len(steps_gt['intermediate_steps']) != 0:\n",
    "            if 'Could not parse' in steps_pred['error']:\n",
    "                assistant_thought = steps_pred['error'].split('Could not parse LLM output: `')[1][:-1]\n",
    "                error = steps_pred['error']\n",
    "                # concatenate hallucination error with ground truth correct thought\n",
    "                sample_w_hallucinations[idx]['Instructions'].append(query_gt)\n",
    "                item_gt_copy = deepcopy(steps_gt)\n",
    "                item_gt_copy['intermediate_steps'] = [[['hallucination', 'hallucination', assistant_thought], error]] + item_gt_copy['intermediate_steps']\n",
    "                sample_w_hallucinations[idx]['Instances'].append(item_gt_copy)\n",
    "                count_hallucinations += 1\n",
    "\n",
    "sample_w_hallucinations_final = []\n",
    "for item in sample_w_hallucinations:\n",
    "    if len(item['Instructions']) > 0:\n",
    "        sample_w_hallucinations_final.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_w_hallucinations_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sample_w_corrections = sample_w_error_corrections_final_w_gpt_output + sample_w_hallucinations_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(final_sample_w_corrections, open('../data/correction_examples_wrong_params_hallucinations.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрю на то, как выглядит промпт в обучающей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.agent_prompts import test_prompt_v1\n",
    "from agent.custom_agent import CustomZeroShotAgent\n",
    "from agent.tools import Tool, GetDetailsTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [GetDetailsTool()]\n",
    "prompt = CustomZeroShotAgent.create_prompt(\n",
    "        tools,\n",
    "        prefix=test_prompt_v1[\"prefix\"],\n",
    "        suffix=test_prompt_v1[\"suffix\"],\n",
    "        format_instructions=test_prompt_v1[\"format_instructions\"],\n",
    "        input_variables=[\"input\", \"agent_scratchpad\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt.format(input='test', agent_scratchpad=\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим тренировочные данные, чтобы посмотреть на формат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = json.load(open('data/train_data_correction_examples_wrong_params', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим train на train и val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part, val_part = data_ground_truth[:268], data_ground_truth[268:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(train_part, open('../data/train_data_train_part.json', 'w'))\n",
    "json.dump(val_part, open('../data/train_data_val_part.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
