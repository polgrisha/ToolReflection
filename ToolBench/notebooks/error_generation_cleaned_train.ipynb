{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../toolbench/inference')\n",
    "from toolbench.inference.LLM.tool_llama_model import ToolLLaMA\n",
    "import argparse\n",
    "import os\n",
    "sys.argv = ['']\n",
    "from toolbench.utils import (\n",
    "    standardize,\n",
    "    change_name,\n",
    "    replace_llama_with_condense\n",
    ")\n",
    "from toolbench.inference.utils import SimpleChatIO, generate_stream, react_parser\n",
    "from toolbench.inference.Downstream_tasks.rapidapi import pipeline_runner, rapidapi_wrapper\n",
    "import json\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import GenerationConfig\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('data/toolbench_new_1311/cleaned_toolllama_G123_dfs_train_downloaded1311_no_undetectable_errors_final.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_max_seq_length = 4096\n",
    "max_seq_length = 8192\n",
    "ratio = int(max_seq_length/source_max_seq_length)\n",
    "replace_llama_with_condense(ratio=ratio)\n",
    "model = ToolLLaMA('data/ToolLLaMA-2-7b-v2', max_sequence_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_model_output(text):\n",
    "    thought, action, action_input = react_parser(text)\n",
    "    message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": thought,\n",
    "        \"function_call\": {\n",
    "            \"name\": action,\n",
    "            \"arguments\": action_input\n",
    "        }\n",
    "    }\n",
    "    return message\n",
    "\n",
    "result = []\n",
    "for item_idx, item in enumerate(tqdm(data)):\n",
    "    res_item = copy.deepcopy(item)\n",
    "    res_item['predictions'] = []\n",
    "    chain = copy.deepcopy(item['conversations'])\n",
    "    for step in chain:\n",
    "        step['role'] = step['from']\n",
    "        step['content'] = step['value']\n",
    "        del step['from']\n",
    "        del step['value']\n",
    "    for i, step in enumerate(chain):\n",
    "        if step['role'] == 'assistant':\n",
    "            thought, action, action_input = react_parser(step['content'])\n",
    "            if action != 'Finish':\n",
    "                gt_message = {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": thought,\n",
    "                    \"function_call\": {\n",
    "                        \"name\": action,\n",
    "                        \"arguments\": action_input\n",
    "                    }\n",
    "                }\n",
    "                model.change_messages(chain[:i])\n",
    "                prompt = model.return_prompt(None, 0)\n",
    "                pred_messages = model.prediction_non_stream(prompt, num_return_seqs=2, temp=1.5, \n",
    "                                                            top_k=100, penalty_alpha=10.0)\n",
    "                pred_messages = [parse_model_output(message) for message in pred_messages]\n",
    "                res_item['predictions'].append({'chain_idx': i,\n",
    "                                                'ground_truth': gt_message,\n",
    "                                                'prediction': pred_messages}) \n",
    "                print(res_item['predictions'][-1])\n",
    "    result.append(res_item)\n",
    "    if item_idx > 0 and item_idx % 100 == 0:\n",
    "        json.dump(result, open('data/toolbench_new_1311/self_correction/generated_errors_no_undetectable_errors.json', 'w'))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
