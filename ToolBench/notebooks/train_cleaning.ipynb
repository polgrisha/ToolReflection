{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "import sys\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM, LlamaTokenizer\n",
    "import json\n",
    "import torch\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = 'data/Llama-2-7b-chat-hf'\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "        load_in_4bit=True,\n",
    "        local_files_only=True,\n",
    "        device_map='auto',\n",
    ")\n",
    "model.config.use_cache = False\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_errors = json.load(open('data/toolbench_new_1311/cleaned_toolllama_G123_dfs_train_downloaded1311_errors_kept.json', 'r'))\n",
    "len(data_no_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_error(content: str):\n",
    "    error_message = re.findall('{\"error\": ?\"([\\s\\S]*)\", \"response\"', content)\n",
    "    if len(error_message) == 0:\n",
    "        error_message = re.findall('{error: ?\"([\\s\\S]*)\"', content)\n",
    "    assert len(error_message) == 1\n",
    "    error_message = error_message[0]\n",
    "\n",
    "    if \"response\" in content and not re.search(\"\\}\\s?$\", content):\n",
    "        content = content + \"}\"\n",
    "        if not re.search(\"[\\\"']\\}$\", content):\n",
    "            content = content[:-1] + \"\\\"\" + \"}\"\n",
    "\n",
    "    if \"API not working\" in error_message or \\\n",
    "        \"Unauthorized\" in error_message or \\\n",
    "        \"Unsubscribed\" in error_message or \\\n",
    "        \"Request timeout\" in error_message or \\\n",
    "        \"Blocked\" in error_message or \\\n",
    "        \"unavailable\" in error_message.lower() or \\\n",
    "        \"request invalid, data error. status_code=5\" in error_message or \\\n",
    "        \"'status': 5\" in content:\n",
    "        return \"Request error\"\n",
    "    \n",
    "    if \"No such function name:\" in error_message:\n",
    "        return \"Wrong API error\"\n",
    "    \n",
    "    if \"Rate limit per minute\" in error_message:\n",
    "        return \"Rate limit error\"\n",
    "    \n",
    "    if \"request invalid, data error\" in error_message and \"status_code=\" not in error_message:\n",
    "        return \"Invalid format error\"\n",
    "    \n",
    "    try:\n",
    "        json_response = json.loads(content)\n",
    "\n",
    "        if \"Message error...\" in error_message and json_response.get(\"response\") is not None:\n",
    "            return json_response.get(\"response\")\n",
    "\n",
    "        if (not json_response.get('response') or \\\n",
    "                 json_response.get(\"response\") is None or \\\n",
    "                 json_response.get(\"response\") == \"[]\") and \\\n",
    "                not json_response.get(\"error\"):\n",
    "            return \"Empty output\"\n",
    "        \n",
    "        if json_response[\"error\"].strip():\n",
    "            return json_response[\"error\"]    \n",
    "    except: pass\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чистка примеров с \"This is not the first time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_errors_no_this_is_not_the_first_time = []\n",
    "\n",
    "for item in data_no_errors:\n",
    "    flag = True\n",
    "    for step in item['conversations']:\n",
    "        if step['from'] == 'user':\n",
    "            if 'This is not the first time' in step['value']:\n",
    "                flag = False\n",
    "    if flag:\n",
    "        data_no_errors_no_this_is_not_the_first_time.append(item)\n",
    "\n",
    "len(data_no_errors_no_this_is_not_the_first_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чистка примеров с детектируемыми ошибками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_detectable_errors = []\n",
    "# for item in data\n",
    "for item in data_no_errors_no_this_is_not_the_first_time:\n",
    "    flag = True\n",
    "    for step in item['conversations']:\n",
    "        if step['from'] == 'function':\n",
    "            if detect_error(step['value']):\n",
    "                flag = False\n",
    "    if flag:\n",
    "        data_no_detectable_errors.append(item)\n",
    "len(data_no_detectable_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чистка примеров недетектируемыми ошибками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "You are you will be given api calls from some model and api outputs from rapidapi apis. \n",
    "Sometimes api return errors. \n",
    "It is hard to parse them using rule-based methods. \n",
    "An api may respond with an empty output (it could be empty list, or an empty dict), contain a field that states it is an error or etc.\n",
    "You will be given 5 examples. You should respond only \"Yes\" if the response does not contain errors from an api and \"No\" if not.\n",
    "Please make shure that api returned what the api call requested. If not, return \"No\"\n",
    "Examples:\n",
    "API Call:\n",
    "Thought: To fulfill the user's request for gathering user information and recent media posts from Instagram for a specific username 'nike', I previously called the 'userinfo_for_instagram_cheapest' function with the argument {\"username\": \"nike\"}. By doing so, I efficiently retrieved the desired user data, including their biography, bio links, biographical information, and other relevant details. Now, to proceed with accessing the user's recent media posts, I will call the 'user_medias_for_instagram_cheapest' function with the argument {\"user_id\": \"113294420064920\"}. This will allow me to retrieve the most recent media posts of the user 'nike' and provide the user with the requested data effectively.\n",
    "Action: user_medias_for_instagram_cheapest\n",
    "Action Input: {\n",
    "  \"user_id\": \"113294420064920\"\n",
    "}\n",
    "API Response:\n",
    "{\"error\": \"\", \"response\": \"{'items': [], 'num_results': 0, 'status': 'ok'}\"}\n",
    "Result:\n",
    "No\n",
    "###\n",
    "API Call:\n",
    "Thought: The user requested the list of languages supported by the LanguageTool API for grammar and writing assistance. To fulfill this request, I need to call the \"list_of_languages_for_languagetool\" function without any arguments. By doing so, I expect to receive the complete list of supported languages. This information will be crucial for implementing multilingual support in the project, ensuring accurate grammar and writing assistance for different languages.\n",
    "Action: list_of_languages_for_languagetool\n",
    "Action Input: {}\n",
    "API Response:\n",
    "{\"error\": \"\", \"response\": \"[{'name': 'Arabic', 'code': 'ar', 'longCode': 'ar'}, {'name': 'Asturian', 'code': 'ast', 'longCode': 'ast-ES'}, {'name': 'Belarusian', 'code': 'be', 'longCode': 'be-BY'}, {'name': 'Breton', 'code': 'br', 'longCode': 'br-FR'}, {'name': 'Catalan', 'code': 'ca', 'longCode': 'ca-ES'}, {'name': 'Catalan (Valencian)', 'code': 'ca', 'longCode': 'ca-ES-valencia'}, {'name': 'Catalan (Balearic)', 'code': 'ca', 'longCode': 'ca-ES-balear'}, {'name': 'Danish', 'code': 'da', 'longCode': 'da-DK'}, {'name': 'German', 'code': 'de', 'longCode': 'de'}, {'name': 'German (Germany)', 'code': 'de', 'longCode': 'de-DE'}, {'name': 'German (Austria)', 'code': 'de', 'longCode': 'de-AT'}, {'name': 'German (Swiss)', 'code': 'de', 'longCode': 'de-CH'}, {'name': 'Simple German', 'code': 'de-DE-x-simple-language', 'longCode': 'de-DE-x-simple-language'}, {'name': 'Greek', 'code': 'el', 'longCode': 'el-GR'}, {'name': 'English', 'code': 'en', 'longCode': 'en'}, {'name': 'English (US)', 'code': 'en', 'longCode': 'en-U..\n",
    "Result:\n",
    "Yes\n",
    "###\n",
    "API Call:\n",
    "Thought: I will now call the \"dividends_for_freedom_finance\" function to retrieve information about dividends for the symbol \"AMZN\". By using the argument {\"symbol\": \"AMZN\"}, I can focus specifically on the dividends related to the stock \"AMZN\". This function will help me analyze the dividend history for \"AMZN\" and provide the user with the requested information.\n",
    "Action: dividends_for_freedom_finance\n",
    "Action Input: {\n",
    "\"symbol\": \"AMZN\"\n",
    "}\n",
    "API Response:\n",
    "{\"error\": \"\", \"response\": \"{'total': 0, 'offset': 0, 'results': [], 'responseStatus': None}\"}\n",
    "Result:\n",
    "No\n",
    "###\n",
    "API Call:\n",
    "Thought: To gather the required information for integrating APIs into the company's website, I can call the \"list_all_api_for_testing_for_my_use\" function. This function will provide me with descriptions, methods, required parameters, and optional parameters for each API. With this information, I can analyze and compare the APIs to make an informed decision.\n",
    "Action: list_all_api_for_testing_for_my_use\n",
    "Action Input: {}\n",
    "API Response:\n",
    "{\"error\": \"Unauthorized error...\", \"response\": \"{'1forge.com': {'added': '2017-05-30T08:34:14.000Z', 'preferred': '0.0.1', 'versions': {'0.0.1': {'added': '2017-05-30T08:34:14.000Z', 'info': {'contact': {'email': 'contact@1forge.com', 'name': '1Forge', 'url': 'http://1forge.com'}, 'description': 'Stock and Forex Data and Realtime Quotes', 'title': '1Forge Finance APIs', 'version': '0.0.1', 'x-apisguru-categories': ['financial'], 'x-logo': {'backgroundColor': '#24292e', 'url': 'https://api.apis.guru/v2/cache/logo/https_1forge.com_assets_images_f-blue.svg'}, 'x-origin': [{'format': 'swagger', 'url': 'http://1forge.com/openapi.json', 'version': '2.0'}], 'x-providerName': '1forge.com'}, 'updated': '2017-06-27T16:49:57.000Z', 'swaggerUrl': 'https://api.apis.guru/v2/specs/1forge.com/0.0.1/swagger.json', 'swaggerYamlUrl': 'https://api.apis.guru/v2/specs/1forge.com/0.0.1/swagger.yaml', 'openapiVer': '2.0', 'link': 'https://api.apis.guru/v2/specs/1forge.com/0.0.1.json'}}}, '1password.com:events': {'added': '2021-07-19...\n",
    "Result:\n",
    "No\n",
    "###\n",
    "API Call:\n",
    "Thought: I need to gather user information for a specific Instagram username, 'nike', as requested by the user. They also want access to the user's recent media posts. To achieve this, I will call the 'userinfo_for_instagram_cheapest' function with the argument of {\"username\": \"nike\"}. This will help me retrieve the desired data efficiently and fulfill the user's request effectively.\n",
    "Action: userinfo_for_instagram_cheapest\n",
    "Action Input: {\n",
    "  \"username\": \"nike\"\n",
    "}\n",
    "API Response:\n",
    "{\"error\": \"\", \"response\": \"{'data': {'user': {'biography': 'Spotlighting athlete* and\\\\xa0\\ud83d\\udc5f\\\\xa0stories\\\\n#BlackLivesMatter, #StopAsianHate, and #NoPrideNoSport', 'bio_links': [{'title': '', 'lynx_url': 'https://l.instagram.com/?u=https%3A%2F%2Flinkin.bio%2Fnike&e=AT063fG4N158ZbZOaZ_A32batiXwR-0Yih5XNa5wfSNPCiDo546PSV0a8mm72ElVxWgNJdgYeHNOTMMTOe_kn7R-C-f2N9ym', 'url': 'https://linkin.bio/nike', 'link_type': 'external'}], 'biography_with_entities': {'raw_text': 'Spotlighting athlete* and\\\\xa0\\ud83d\\udc5f\\\\xa0stories\\\\n#BlackLivesMatter, #StopAsianHate, and #NoPrideNoSport', 'entities': [{'user': None, 'hashtag': {'name': 'nopridenosport'}}, {'user': None, 'hashtag': {'name': 'stopasianhate'}}, {'user': None, 'hashtag': {'name': 'blacklivesmatter'}}]}, 'blocked_by_viewer': False, 'restricted_by_viewer': None, 'country_block': False, 'eimu_id': '113294420064920', 'external_url': 'https://linkin.bio/nike', 'external_url_linkshimmed': 'https://l.instagram.com/?u=https%3A%2F%2Flinkin.bio%2Fnike&e=AT04S69...\n",
    "Result:\n",
    "Yes\n",
    "###\n",
    "API Call: \n",
    "<api_call>\n",
    "API Response:\n",
    "<api_response>\n",
    "Result:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_detectable_errors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_undetectable_errors = []\n",
    "for item in tqdm(data_no_detectable_errors[8839:]):\n",
    "    predictions = []\n",
    "    flag = True\n",
    "    for i, step in enumerate(item['conversations']):\n",
    "        if step['from'] == 'assistant' and i != len(item['conversations'])-1:\n",
    "            api_call = str(step['value'])\n",
    "            api_response = str(item['conversations'][i+1]['value'])\n",
    "            curr_prompt = prompt.replace('<api_call>', api_call)\n",
    "            curr_prompt = curr_prompt.replace('<api_response>', api_response)\n",
    "            with torch.no_grad():\n",
    "                tokenized = tokenizer(curr_prompt, return_tensors=\"pt\").input_ids\n",
    "                res = model.generate(tokenized, max_length=tokenized.shape[1] + 1)\n",
    "                pred = tokenizer.batch_decode(res)[0].removeprefix(tokenizer.batch_decode(tokenized)[0])\n",
    "                print(api_response)\n",
    "                print(pred)\n",
    "                print('#' * 100)\n",
    "                if pred != 'Yes':\n",
    "                    flag = False\n",
    "                    break\n",
    "    if flag:\n",
    "        data_no_undetectable_errors.append(item)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item_ in enumerate(tqdm(data_no_detectable_errors)):\n",
    "    if item_ == item:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "5852 / 8839"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "1111 * 60 / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "156 * 60 / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_no_undetectable_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_undetectable_errors[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_no_undetectable_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним данные для дальнейшего использования "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_undetectable_errors_part_1 = json.load(open('data/toolbench_new_1311/cleaned_toolllama_G123_dfs_train_downloaded1311_no_undetectable_errors.json', 'r'))\n",
    "len(data_no_undetectable_errors_part_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(data_no_undetectable_errors, open('data/toolbench_new_1311/cleaned_toolllama_G123_dfs_train_downloaded1311_no_undetectable_errors_part_2.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_undetectable_errors_all = data_no_undetectable_errors_part_1 + data_no_undetectable_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(data_no_undetectable_errors_all, open('data/toolbench_new_1311/cleaned_toolllama_G123_dfs_train_downloaded1311_no_undetectable_errors_final.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_undetectable_errors = json.load(open('data/toolbench_new_1311/cleaned_toolllama_G123_dfs_train_downloaded1311_no_undetectable_errors_final.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_undetectable_errors_part_1 = json.load(open('data/toolbench_new_1311/cleaned_toolllama_G123_dfs_train_downloaded1311_no_undetectable_errors.json', 'r'))\n",
    "len(data_no_undetectable_errors_part_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_undetectable_errors_part_2 = json.load( open('data/toolbench_new_1311/cleaned_toolllama_G123_dfs_train_downloaded1311_no_undetectable_errors_part_2.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_no_undetectable_errors_part_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_undetectable_errors_final = data_no_undetectable_errors_part_1 + data_no_undetectable_errors_part_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на assistant messages, потому что в оригинале модель обучается на последнем сообщении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_undetectable_errors_final[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_undetectable_errors_final_splitted = []\n",
    "for item in data_no_undetectable_errors_final:\n",
    "    conversations = item['conversations']\n",
    "    for i in range(len(conversations)):\n",
    "        if conversations[i]['from'] == 'assistant':\n",
    "            splitted_item = deepcopy(item)\n",
    "            splitted_item['conversations'] = splitted_item['conversations'][:i+1]\n",
    "            data_no_undetectable_errors_final_splitted.append(splitted_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_no_undetectable_errors_final_splitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(data_no_undetectable_errors_final_splitted, open('data/toolbench_new_1311/cleaned_toolllama_G123_dfs_train_downloaded1311_no_undetectable_errors_final_splitted.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train = json.load(open('/data5/okhotnikov/alpaca-lora/ToolBench/toolllama_G123_dfs_train_downloaded1311.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(original_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
