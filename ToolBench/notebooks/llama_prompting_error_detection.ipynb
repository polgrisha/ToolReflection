{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "import sys\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM, LlamaTokenizer\n",
    "import json\n",
    "import torch\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = 'data/Llama-2-7b-chat-hf'\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "        load_in_4bit=True,\n",
    "        local_files_only=True,\n",
    "        device_map='auto',\n",
    ")\n",
    "model.config.use_cache = False\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_prompt = \"What does the fllowing sentence say? Translate to english. \\u6c7d\\u6c34\\u74f6\\u5851\\u6599\\u676f\\u900f\\u660e\\u78e8\\u7802\\u4fbf\\u643a\\u4e0d\\u6613\\u6454\\u7834\\u5bc6\\u5c01\\u540a\\u5e26\\u5976\\u8336\\u676f\\u6c34\\u676f\\u505a\\u793c\\u54c1 Translation:\"\n",
    "tokenized = tokenizer(curr_prompt, return_tensors=\"pt\").input_ids\n",
    "res = model.generate(tokenized, max_length=tokenized.shape[1] + 2)\n",
    "print(tokenizer.batch_decode(res)[0].removeprefix(tokenizer.batch_decode(tokenized)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "You are you will be given api calls from some model and api outputs from rapidapi apis. \n",
    "Sometimes api return errors. \n",
    "It is hard to parse them using rule-based methods. \n",
    "An api may respond with an empty output (it could be empty list, or an empty dict), contain a field that states it is an error or etc.\n",
    "You will be given 5 examples. You should respond only \"Yes\" if the response does not contain errors from an api and \"No\" if not.\n",
    "Please make shure that api returned what the api call requested. If not, return \"No\"\n",
    "Examples:\n",
    "API Call:\n",
    "Thought: To fulfill the user's request for gathering user information and recent media posts from Instagram for a specific username 'nike', I previously called the 'userinfo_for_instagram_cheapest' function with the argument {\"username\": \"nike\"}. By doing so, I efficiently retrieved the desired user data, including their biography, bio links, biographical information, and other relevant details. Now, to proceed with accessing the user's recent media posts, I will call the 'user_medias_for_instagram_cheapest' function with the argument {\"user_id\": \"113294420064920\"}. This will allow me to retrieve the most recent media posts of the user 'nike' and provide the user with the requested data effectively.\n",
    "Action: user_medias_for_instagram_cheapest\n",
    "Action Input: {\n",
    "  \"user_id\": \"113294420064920\"\n",
    "}\n",
    "API Response:\n",
    "{\"error\": \"\", \"response\": \"{'items': [], 'num_results': 0, 'status': 'ok'}\"}\n",
    "Result:\n",
    "No\n",
    "###\n",
    "API Call:\n",
    "Thought: The user requested the list of languages supported by the LanguageTool API for grammar and writing assistance. To fulfill this request, I need to call the \"list_of_languages_for_languagetool\" function without any arguments. By doing so, I expect to receive the complete list of supported languages. This information will be crucial for implementing multilingual support in the project, ensuring accurate grammar and writing assistance for different languages.\n",
    "Action: list_of_languages_for_languagetool\n",
    "Action Input: {}\n",
    "API Response:\n",
    "{\"error\": \"\", \"response\": \"[{'name': 'Arabic', 'code': 'ar', 'longCode': 'ar'}, {'name': 'Asturian', 'code': 'ast', 'longCode': 'ast-ES'}, {'name': 'Belarusian', 'code': 'be', 'longCode': 'be-BY'}, {'name': 'Breton', 'code': 'br', 'longCode': 'br-FR'}, {'name': 'Catalan', 'code': 'ca', 'longCode': 'ca-ES'}, {'name': 'Catalan (Valencian)', 'code': 'ca', 'longCode': 'ca-ES-valencia'}, {'name': 'Catalan (Balearic)', 'code': 'ca', 'longCode': 'ca-ES-balear'}, {'name': 'Danish', 'code': 'da', 'longCode': 'da-DK'}, {'name': 'German', 'code': 'de', 'longCode': 'de'}, {'name': 'German (Germany)', 'code': 'de', 'longCode': 'de-DE'}, {'name': 'German (Austria)', 'code': 'de', 'longCode': 'de-AT'}, {'name': 'German (Swiss)', 'code': 'de', 'longCode': 'de-CH'}, {'name': 'Simple German', 'code': 'de-DE-x-simple-language', 'longCode': 'de-DE-x-simple-language'}, {'name': 'Greek', 'code': 'el', 'longCode': 'el-GR'}, {'name': 'English', 'code': 'en', 'longCode': 'en'}, {'name': 'English (US)', 'code': 'en', 'longCode': 'en-U..\n",
    "Result:\n",
    "Yes\n",
    "###\n",
    "API Call:\n",
    "Thought: I will now call the \"dividends_for_freedom_finance\" function to retrieve information about dividends for the symbol \"AMZN\". By using the argument {\"symbol\": \"AMZN\"}, I can focus specifically on the dividends related to the stock \"AMZN\". This function will help me analyze the dividend history for \"AMZN\" and provide the user with the requested information.\n",
    "Action: dividends_for_freedom_finance\n",
    "Action Input: {\n",
    "\"symbol\": \"AMZN\"\n",
    "}\n",
    "API Response:\n",
    "{\"error\": \"\", \"response\": \"{'total': 0, 'offset': 0, 'results': [], 'responseStatus': None}\"}\n",
    "Result:\n",
    "No\n",
    "###\n",
    "API Call:\n",
    "Thought: To gather the required information for integrating APIs into the company's website, I can call the \"list_all_api_for_testing_for_my_use\" function. This function will provide me with descriptions, methods, required parameters, and optional parameters for each API. With this information, I can analyze and compare the APIs to make an informed decision.\n",
    "Action: list_all_api_for_testing_for_my_use\n",
    "Action Input: {}\n",
    "API Response:\n",
    "{\"error\": \"Unauthorized error...\", \"response\": \"{'1forge.com': {'added': '2017-05-30T08:34:14.000Z', 'preferred': '0.0.1', 'versions': {'0.0.1': {'added': '2017-05-30T08:34:14.000Z', 'info': {'contact': {'email': 'contact@1forge.com', 'name': '1Forge', 'url': 'http://1forge.com'}, 'description': 'Stock and Forex Data and Realtime Quotes', 'title': '1Forge Finance APIs', 'version': '0.0.1', 'x-apisguru-categories': ['financial'], 'x-logo': {'backgroundColor': '#24292e', 'url': 'https://api.apis.guru/v2/cache/logo/https_1forge.com_assets_images_f-blue.svg'}, 'x-origin': [{'format': 'swagger', 'url': 'http://1forge.com/openapi.json', 'version': '2.0'}], 'x-providerName': '1forge.com'}, 'updated': '2017-06-27T16:49:57.000Z', 'swaggerUrl': 'https://api.apis.guru/v2/specs/1forge.com/0.0.1/swagger.json', 'swaggerYamlUrl': 'https://api.apis.guru/v2/specs/1forge.com/0.0.1/swagger.yaml', 'openapiVer': '2.0', 'link': 'https://api.apis.guru/v2/specs/1forge.com/0.0.1.json'}}}, '1password.com:events': {'added': '2021-07-19...\n",
    "Result:\n",
    "No\n",
    "###\n",
    "API Call:\n",
    "Thought: I need to gather user information for a specific Instagram username, 'nike', as requested by the user. They also want access to the user's recent media posts. To achieve this, I will call the 'userinfo_for_instagram_cheapest' function with the argument of {\"username\": \"nike\"}. This will help me retrieve the desired data efficiently and fulfill the user's request effectively.\n",
    "Action: userinfo_for_instagram_cheapest\n",
    "Action Input: {\n",
    "  \"username\": \"nike\"\n",
    "}\n",
    "API Response:\n",
    "{\"error\": \"\", \"response\": \"{'data': {'user': {'biography': 'Spotlighting athlete* and\\\\xa0\\ud83d\\udc5f\\\\xa0stories\\\\n#BlackLivesMatter, #StopAsianHate, and #NoPrideNoSport', 'bio_links': [{'title': '', 'lynx_url': 'https://l.instagram.com/?u=https%3A%2F%2Flinkin.bio%2Fnike&e=AT063fG4N158ZbZOaZ_A32batiXwR-0Yih5XNa5wfSNPCiDo546PSV0a8mm72ElVxWgNJdgYeHNOTMMTOe_kn7R-C-f2N9ym', 'url': 'https://linkin.bio/nike', 'link_type': 'external'}], 'biography_with_entities': {'raw_text': 'Spotlighting athlete* and\\\\xa0\\ud83d\\udc5f\\\\xa0stories\\\\n#BlackLivesMatter, #StopAsianHate, and #NoPrideNoSport', 'entities': [{'user': None, 'hashtag': {'name': 'nopridenosport'}}, {'user': None, 'hashtag': {'name': 'stopasianhate'}}, {'user': None, 'hashtag': {'name': 'blacklivesmatter'}}]}, 'blocked_by_viewer': False, 'restricted_by_viewer': None, 'country_block': False, 'eimu_id': '113294420064920', 'external_url': 'https://linkin.bio/nike', 'external_url_linkshimmed': 'https://l.instagram.com/?u=https%3A%2F%2Flinkin.bio%2Fnike&e=AT04S69...\n",
    "Result:\n",
    "Yes\n",
    "###\n",
    "API Call: \n",
    "<api_call>\n",
    "API Response:\n",
    "<api_response>\n",
    "Result:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_zero_shot = '''\n",
    "You are you will be api calls from some model and api outputs from rapidapi apis. \n",
    "Sometimes api return errors. \n",
    "It is hard to parse them using rule-based methods. \n",
    "An api may respond with an empty output (it could be empty list, or an empty dict), contain a field that states it is an error or etc.\n",
    "You will be given 5 examples. You should respond only \"Yes\" if the response does not contain errors from an api and \"No\" if not.\n",
    "Please make shure that api returned what the api call requested. If not, return \"No\"\n",
    "You will be given data in the folllowing format.\n",
    "API Call: \n",
    "api_call\n",
    "API Response:\n",
    "api_response\n",
    "Result: \n",
    "Yes/No\n",
    "Begin!\n",
    "###\n",
    "API Call: \n",
    "<api_call>\n",
    "API Response:\n",
    "<api_response>\n",
    "Result:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('data/toolbench_new_1311/cleaned_toolllama_G123_dfs_train_downloaded1311_no_this_is_not_the_first_time_you_tried.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in data[:10]:\n",
    "    flag = True\n",
    "    for i, step in enumerate(item['conversations']):\n",
    "        if step['from'] == 'function':\n",
    "            curr_prompt = prompt.replace('<api_call>', item['conversations'][i-1]['value'])\n",
    "            curr_prompt = curr_prompt.replace('<api_response>', step['value'])\n",
    "            with torch.no_grad():\n",
    "                tokenized = tokenizer(curr_prompt, return_tensors=\"pt\").input_ids\n",
    "                res = model.generate(tokenized, max_length=tokenized.shape[1] + 2)\n",
    "                print('API Call:')\n",
    "                print(item['conversations'][i-1]['value'])\n",
    "                print('API Response:')\n",
    "                print(step['value'])\n",
    "                print('Result:')\n",
    "                print(tokenizer.batch_decode(res)[0].removeprefix(tokenizer.batch_decode(tokenized)[0]))\n",
    "                print('#' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прогоню модель на тесте, который у меня получился"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/self_correction/error_test_data/test_marked.txt', 'r') as f:\n",
    "    test_data = f.read()\n",
    "test_items = test_data.split('\\n###################################################################\\n')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for item in tqdm(test_items):\n",
    "    api_call = item.split('API Call: \\n')[1].split('\\nAPI Response')[0]\n",
    "    api_response = item.split('API Response:\\n')[1].split('\\nResult:')[0]\n",
    "    curr_prompt = prompt.replace('<api_call>', api_call)\n",
    "    curr_prompt = curr_prompt.replace('<api_response>', api_response)\n",
    "    with torch.no_grad():\n",
    "        tokenized = tokenizer(curr_prompt, return_tensors=\"pt\").input_ids\n",
    "        res = model.generate(tokenized, max_length=tokenized.shape[1] + 1)\n",
    "        pred = tokenizer.batch_decode(res)[0].removeprefix(tokenizer.batch_decode(tokenized)[0])\n",
    "        predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for item in test_items:\n",
    "    ans = item.split('Result:\\n')[1].strip()\n",
    "    answers.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "tp = 0\n",
    "tn = 0\n",
    "for gt, pred in zip(answers, predictions):\n",
    "    if gt == pred:\n",
    "        acc += 1\n",
    "        if gt == 'No':\n",
    "            tn += 1\n",
    "        else:\n",
    "            tp += 1\n",
    "    elif gt == 'No' and pred == 'Yes':\n",
    "        fp += 1\n",
    "    else:\n",
    "        fn += 1\n",
    "print(f'Accuracy: {acc}, Precision: {tp / (tp + fp)}, Recall: {tp / (tp + fn)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим на результаты на новом тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/self_correction/error_test_data/final_test_balanced_marked.json', 'r') as f:\n",
    "    balanced_test = json.load(f)\n",
    "\n",
    "balanced_test[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_balanced_test = []\n",
    "for item in tqdm(balanced_test):\n",
    "    api_call = item['api_call']\n",
    "    api_response = item['api_response']\n",
    "    curr_prompt = prompt_zero_shot.replace('<api_call>', api_call)\n",
    "    curr_prompt = curr_prompt.replace('<api_response>', api_response)\n",
    "    with torch.no_grad():\n",
    "        tokenized = tokenizer(curr_prompt, return_tensors=\"pt\").input_ids\n",
    "        res = model.generate(tokenized, max_length=tokenized.shape[1] + 1)\n",
    "        pred = tokenizer.batch_decode(res)[0].removeprefix(tokenizer.batch_decode(tokenized)[0])\n",
    "        predictions_balanced_test.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_balanced_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_balanced_test = [item['label'] for item in balanced_test]\n",
    "\n",
    "acc = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "tp = 0\n",
    "tn = 0\n",
    "for gt, pred in zip(answers_balanced_test, predictions_balanced_test):\n",
    "    if gt == pred:\n",
    "        acc += 1\n",
    "        if gt == 'Yes':\n",
    "            tn += 1\n",
    "        else:\n",
    "            tp += 1\n",
    "    elif gt == 'Yes' and pred == 'No':\n",
    "        fp += 1\n",
    "    else:\n",
    "        fn += 1\n",
    "print(f'Accuracy: {acc}, Precision: {tp / (tp + fp)}, Recall: {tp / (tp + fn)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
