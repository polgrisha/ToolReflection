{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_original = json.load(open('data/toolbench_new_1311/cleaned_toolllama_G123_dfs_train_downloaded1311_no_undetectable_errors_final.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_original[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tool_set(item):\n",
    "    tool_system_msg = \"You have access of the following tools:\\n\"\n",
    "    api_system_msg = \"\\nSpecifically, you have access to the following APIs: \"\n",
    "\n",
    "    system_step = item['conversations'][0]['value']\n",
    "\n",
    "    tool_descriptions = system_step.split(tool_system_msg)[1].split(api_system_msg)[0]\n",
    "    tools = system_step.split(api_system_msg)[1]\n",
    "\n",
    "    try:\n",
    "        tools = yaml.load(tools, yaml.Loader)\n",
    "        return tools\n",
    "    except Exception as e:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_parseble_tools = []\n",
    "for item in tqdm(train_data_original):\n",
    "    tools = get_tool_set(item)\n",
    "    if tools:\n",
    "        item_parseble_tools = deepcopy(item)\n",
    "        item_parseble_tools['tools'] = tools\n",
    "        train_data_parseble_tools.append(item_parseble_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data_parseble_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tool_set(train_data_original[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_apis = set()\n",
    "all_tools = set()\n",
    "for item in tqdm(train_data_parseble_tools):\n",
    "    curr_tools = item['tools']\n",
    "    for tool in curr_tools:\n",
    "        tool_name = tool['name']\n",
    "        if 'for' in tool_name:\n",
    "            all_tools.add(tool_name.split('_for_')[1])\n",
    "        else:\n",
    "            all_tools.add(tool_name)\n",
    "        all_apis.add(tool['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tool_names(item):\n",
    "    tools = item['tools']\n",
    "    tool_names = set()\n",
    "    for tool in tools:\n",
    "        tool_name = tool['name']\n",
    "        if 'for' in tool_name:\n",
    "            tool_names.add(tool_name.split('_for_')[1])\n",
    "        else:\n",
    "            tool_names.add(tool_name)\n",
    "    return tool_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tools, val_tools = train_test_split(list(all_tools), test_size=0.4)\n",
    "train_tools = set(train_tools)\n",
    "val_tools = set(val_tools)\n",
    "if 'Finish' in val_tools:\n",
    "    val_tools.remove('Finish')\n",
    "    train_tools.add('Finish')\n",
    "print(len(train_tools), len(val_tools))\n",
    "\n",
    "intersection_count = 0\n",
    "for item in tqdm(train_data_parseble_tools):\n",
    "    tools = get_tool_names(item)\n",
    "    tools.remove('Finish')\n",
    "    tools_from_train = tools.intersection(train_tools)\n",
    "    tools_from_val = tools.intersection(val_tools)\n",
    "    if tools_from_train and tools_from_val:\n",
    "        rand = random.uniform(0,1)\n",
    "        if rand >= 0.4:\n",
    "            for tool in tools_from_val:\n",
    "                val_tools.remove(tool)\n",
    "                train_tools.add(tool)\n",
    "        else:\n",
    "            for tool in tools_from_train:\n",
    "                train_tools.remove(tool)\n",
    "                val_tools.add(tool)\n",
    "\n",
    "print(len(train_tools), len(val_tools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_count = 0\n",
    "train_count = 0\n",
    "val_count = 0\n",
    "\n",
    "train_sample = []\n",
    "val_sample = []\n",
    "for item in tqdm(train_data_parseble_tools):\n",
    "    tools = get_tool_names(item)\n",
    "    tools.remove('Finish')\n",
    "    tools_from_train = tools.intersection(train_tools)\n",
    "    tools_from_val = tools.intersection(val_tools)\n",
    "    if tools_from_train:\n",
    "        train_count += 1\n",
    "    if tools_from_val:\n",
    "        val_count += 1\n",
    "    if tools_from_train and tools_from_val:\n",
    "        intersection_count += 1\n",
    "\n",
    "    if tools_from_train and not tools_from_val:\n",
    "        train_sample.append(item)\n",
    "    else:\n",
    "        val_sample.append(item)\n",
    "        \n",
    "print(train_count, val_count, intersection_count)\n",
    "print(len(train_sample))\n",
    "print(len(val_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data_original))\n",
    "print(len(train_data_parseble_tools))\n",
    "print(len(train_sample))\n",
    "print(len(val_sample))\n",
    "print(len(train_sample) + len(val_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_last_tool_call(data):\n",
    "    data_splitted = []\n",
    "    for item in data:\n",
    "        conversations = item['conversations']\n",
    "        for i in range(len(conversations)):\n",
    "            if conversations[i]['from'] == 'assistant':\n",
    "                splitted_item = deepcopy(item)\n",
    "                splitted_item['conversations'] = splitted_item['conversations'][:i+1]\n",
    "                data_splitted.append(splitted_item)\n",
    "    return data_splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_original_splitted = split_data_last_tool_call(train_data_original)\n",
    "len(train_original_splitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_splitted = split_data_last_tool_call(train_sample)\n",
    "val_sample_splitted = split_data_last_tool_call(val_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_sample_splitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_sample_splitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(train_sample_splitted, open('data/toolbench_new_1311/cleaned_toolllama_G123_dfs_train_downloaded1311_no_undetectable_errors_final_train_train.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(val_sample_splitted, open('data/toolbench_new_1311/cleaned_toolllama_G123_dfs_train_downloaded1311_no_undetectable_errors_final_train_val.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(train_sample, open('data/toolbench_new_1311/cleaned_toolllama_G123_dfs_train_downloaded1311_no_undetectable_errors_final_train_train_full_chains.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(val_sample, open('data/toolbench_new_1311/cleaned_toolllama_G123_dfs_train_downloaded1311_no_undetectable_errors_final_train_val_full_chains.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
