{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e0b1cf-963f-4962-9b35-e9f13927ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, './')\n",
    "sys.path.insert(0, './toolbench')\n",
    "sys.path.insert(0, './toolbench/inference')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de125fe7-e87a-441d-bd5e-e5ab34b31714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "from toolbench.inference.Downstream_tasks.rapidapi import pipeline_runner\n",
    "from toolbench.inference.Downstream_tasks.rapidapi import rapidapi_wrapper\n",
    "from toolbench.inference.Algorithms.single_chain import single_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e2d305-d2c3-45ad-be28-bc6d9ae2c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--backbone_model', type=str, default=\"toolllama\", required=False, help='chatgpt_function or davinci or toolllama')\n",
    "parser.add_argument('--openai_key', type=str, default=\"\", required=False, help='openai key for chatgpt_function or davinci model')\n",
    "parser.add_argument('--model_path', type=str, default=\"your_model_path/\", required=False, help='')\n",
    "parser.add_argument('--tool_root_dir', type=str, default=\"your_tools_path/\", required=True, help='')\n",
    "parser.add_argument(\"--lora\", action=\"store_true\", help=\"Load lora model or not.\")\n",
    "parser.add_argument('--lora_path', type=str, default=\"your_lora_path if lora\", required=False, help='')\n",
    "parser.add_argument('--max_observation_length', type=int, default=1024, required=False, help='maximum observation length')\n",
    "parser.add_argument('--observ_compress_method', type=str, default=\"truncate\", choices=[\"truncate\", \"filter\", \"random\"], required=False, help='observation compress method')\n",
    "parser.add_argument('--method', type=str, default=\"CoT@1\", required=False, help='method for answer generation: CoT@n,Reflexion@n,BFS,DFS,UCT_vote')\n",
    "parser.add_argument('--input_query_file', type=str, default=\"\", required=False, help='input path')\n",
    "parser.add_argument('--output_answer_file', type=str, default=\"\",required=False, help='output path')\n",
    "parser.add_argument('--toolbench_key', type=str, default=\"\",required=False, help='your toolbench key to request rapidapi service')\n",
    "parser.add_argument('--rapidapi_key', type=str, default=\"\",required=False, help='your rapidapi key to request rapidapi service')\n",
    "parser.add_argument('--use_rapidapi_key', action=\"store_true\", help=\"To use customized rapidapi service or not.\")\n",
    "\n",
    "args = parser.parse_args(['--model_path', 'toolbench/ToolLLaMA-2-7b/', \n",
    "                          '--input_query_file', 'data/toolformer_data_convertion/eval/G1_eval_query.json',\n",
    "                          '--output_answer_file', 'data/answer/test_toollama_2',\n",
    "                          '--toolbench_key', '2TLxGfLkzebcy7trDP4RzqcbnuAFypTHbKlRNvYCGuVsn5Svv3',\n",
    "                          '--tool_root_dir', 'data/toolenv/tools'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b27a90-5df7-49bf-bb55-656195af56ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = pipeline_runner(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82242cec-6150-437c-bfea-a9de3f88ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 6\n",
    "print(runner.task_list[idx][6])\n",
    "print('#' * 100)\n",
    "print(runner.task_list[idx][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f462dc-1cd5-418a-904d-26b1b4ba52df",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4\n",
    "data_dict = runner.task_list[idx][3]\n",
    "args = runner.task_list[idx][4]\n",
    "tool_des = runner.task_list[idx][6]\n",
    "env = rapidapi_wrapper(data_dict, tool_des, None, args, process_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923037fa-e7d3-4b45-a050-f4f6574aaabc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382a2063-38d3-415c-a031-20fa5d837324",
   "metadata": {},
   "outputs": [],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aef133-8da6-4223-8bd9-2b2f0a0e84d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env._step('address_monitor', '{}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e62017-7d83-402e-87bf-29c00dadb451",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.task_list[0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163b4c3f-a84e-45be-a977-cba33a4d5aaf",
   "metadata": {},
   "source": [
    "Попробуем прогнать модель на G1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3620db7-a992-4e9d-8acf-a5d0512dede3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059d7133-0529-49ba-821f-9c652d485e35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "process_id = 0\n",
    "single_chain_max_step = 12\n",
    "\n",
    "for k, task in enumerate(runner.task_list[1:]):\n",
    "    method = task[0]\n",
    "    backbone_model = task[1]\n",
    "    query_id = task[2]\n",
    "    data_dict = task[3]\n",
    "    args = task[4]\n",
    "    tool_des = task[6]\n",
    "    env = rapidapi_wrapper(data_dict, tool_des, None, args, process_id=process_id)\n",
    "\n",
    "    passat = int(method.split(\"@\")[-1])\n",
    "    chain = single_chain(llm=backbone_model, io_func=env, process_id=process_id)\n",
    "    chain.start(pass_at=passat,\n",
    "                single_chain_max_step=single_chain_max_step,\n",
    "                answer=1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd57a73d-5f07-47d6-8de8-88594e78847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.tree[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8a080f-4c60-43f8-808f-016781482774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chain.terminal_node[0].get_chain_result_from_this_node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522ba918-7d59-44cd-953e-273b55fd52ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.tool_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04be56a9-4802-453b-81dd-33ec4351c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.task_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09e2103-3845-4025-8bde-ac73190414d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(backbone_model.conversation_history[0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89ec87-cc33-4c99-b583-9f743160bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_des"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b97b95-0c32-467a-b134-0ec90b6e0dde",
   "metadata": {},
   "source": [
    "Проблема в том, что почему-то в промпте нету описания тулов с параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9a37be-82c4-4eef-82a6-5bb2475a07fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/toolllama_G123_dfs_train.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "data[100]['conversations'][-1]['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69741655-421e-4855-a5e2-cbaf15a001a0",
   "metadata": {},
   "source": [
    "Поменял промпт. Попробую теперь позапускать. Возможно, качество станет лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3bce12-5825-4387-a1d1-a560398505f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_id = 0\n",
    "single_chain_max_step = 12\n",
    "\n",
    "for k, task in enumerate(runner.task_list[70:]):\n",
    "    method = task[0]\n",
    "    backbone_model = task[1]\n",
    "    query_id = task[2]\n",
    "    data_dict = task[3]\n",
    "    args = task[4]\n",
    "    tool_des = task[6]\n",
    "    env = rapidapi_wrapper(data_dict, tool_des, None, args, process_id=process_id)\n",
    "\n",
    "    passat = int(method.split(\"@\")[-1])\n",
    "    chain = single_chain(llm=backbone_model, io_func=env, process_id=process_id)\n",
    "    chain.start(pass_at=passat,\n",
    "                single_chain_max_step=single_chain_max_step,\n",
    "                answer=1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a79c82-6b4c-4f9e-a021-3dfa87f08f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [1, 2, 3]\n",
    "str(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2138730-7976-47d8-aa48-e73acd38d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_model.conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5552c1-5e15-4fb3-9c74-012f1b4a624a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
