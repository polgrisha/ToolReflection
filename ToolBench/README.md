Here, we present the code for obtaining the results of ToolBench. This repository includes the original code from [ToolBench](https://github.com/OpenBMB/ToolBench), along with our enhancements. The most notable additions are:

- **Multistep-100 Evaluation Dataset**:  
  ToolBench primarily relies on automated evaluation, calculating pass rate and win rate using ChatGPT. However, we found this approach challenging to reproduce and prone to high variation in evaluation metrics. Additionally, some tools in the original evaluation set are unavailable.  

  To address these issues:  
  1. We selected 16 APIs from ToolBench, ensuring they were not present in the ToolBench training set.  
  2. We manually annotated 10 query templates with missing parameter values, requiring multiple steps of tool calls.  
  3. We used LLaMA-2 to reformulate these queries, creating a dataset of 100 examples.  
  4. We constructed a table of real parameters (names, IDs, numerical values) and randomly filled missing values in the query templates.  

  Unlike ToolBench, tool invocation steps in this benchmark depend on each other. Therefore, evaluation focuses on the correctness of the final tool calls. We measure the **success rate** of these final calls.

- **ToolReflection Pipeline**:  
  We enhanced the original ToolBench fine-tuning pipeline (ToolLLaMA) by incorporating self-generated examples containing tool-calling errors and their corrections.

### Added and Updated Components

- **`data/Multistep-100/`**:  
  Contains the code to generate the Multistep-100 dataset, the dataset itself, and scripts for evaluating the ToolLLaMA model on it.

- **`data/ToolReflection/`**:  
  Contains the dataset generated through the ToolReflection procedure. This dataset includes tool invocation paths with errors and their corrections, self-generated by ToolLLaMA interacting with various tools. It is used to augment the original ToolBench dataset.

- **`notebooks/`**:  
  Includes Jupyter notebooks for augmenting the dataset using the ToolReflection procedure and for calculating the final accuracy on the Multistep-100 test dataset.